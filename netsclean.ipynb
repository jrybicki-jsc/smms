{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple, Sequence, Callable\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from appknn import app_k_nearest, mysample, calculate_margin, create_net, adf\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_app(appid, labels):\n",
    "    return labels[labels.apn==appid]['malware_label'].values[0]\n",
    "\n",
    "def verify_point(appid, net, labels, k, distance):\n",
    "    n = app_k_nearest(k=k, apps=net, new_app=appid, distance=distance)\n",
    "    if n[0] == appid:\n",
    "        print(\"It found itself... not really a classification\")\n",
    "        \n",
    "    ap_mal = classify_app(appid, labels)\n",
    "    pt_mal = classify_app(n[0], labels)\n",
    "\n",
    "    return ap_mal, pt_mal\n",
    "    \n",
    "\n",
    "def generate_net(v, labels, sample_size, problematic_pairs):\n",
    "    smp = mysample(v, sample_size) #v.sample(sample_size, random_state=42)\n",
    "    print(f\"sample created {smp.shape[0]/v.shape[0]:.2f}\")\n",
    "    if len(problematic_pairs)>0:\n",
    "        problematic = list(itertools.chain(*problematic_pairs))\n",
    "        print(f\"Removing problematic {len(problematic)} apps\")\n",
    "        smp = smp[~smp.apn.isin(problematic)]\n",
    "\n",
    "    funcs_smp = smp.groupby(by='apn')['nf'].apply(set)\n",
    "    margin, problematic_prs = calculate_margin(smp, labels, distance=lambda x,y,z: adf(x,y, funcs_smp))\n",
    "    gamma = margin / 2.0\n",
    "\n",
    "    \n",
    "    problematic = list(itertools.chain(*(problematic_pairs+problematic_prs)))\n",
    "    print(f\"Second removal of problematics {len(problematic)}\")\n",
    "    smp = smp[~smp.apn.isin(problematic)]\n",
    "    #I guess we don't need new dsitance matrix funcs_smp (only removal)\n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(smp.apn.unique())\n",
    "    print(f\"Calculating net with {gamma}\")\n",
    "    net = create_net(gamma=gamma, apns=train, distance=lambda x,y: adf(x,y, funcs_smp))\n",
    "    print(f\"Net {len(net)} of {len(train)} created\")\n",
    "    \n",
    "    return smp, train, test, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv('data/functions_encoded.csv')\n",
    "labels = pd.read_csv('./data/labels_encoded.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "problematic_pairs = [(20353, 11822), (20353, 5960), (20353, 5279), (20353, 23352), (20353, 4508), (20353, 15342), (20353, 2049), (20353, 15167), (20353, 22414), (20353, 9094), (20353, 25173), (20353, 7987), (20353, 10025), (20353, 5217), (20353, 9950), (20353, 24486), (20353, 17737), (20353, 17091), (20353, 24216), (20353, 23845), (20353, 6845), (20353, 25822), (20353, 4544), (20353, 5104), (20353, 1342), (20353, 16752), (20353, 17521), (20353, 5748), (20353, 21368), (20353, 23385), (20353, 24937), (20353, 10917), (20353, 27580), (20353, 17441), (20353, 16741), (20353, 4207), (20353, 8831), (20353, 22246), (20353, 15939), (20353, 21521), (20353, 14873), (20353, 4419), (20353, 23693), (20353, 12381), (20353, 23648), (20353, 12363), (20353, 22947), (20353, 22142), (20353, 17493), (20353, 13548), (20353, 14005), (20353, 14118), (20353, 17489), (20353, 11314), (20353, 23366), (20353, 24831), (20353, 12600), (20353, 22022), (20353, 17768), (20353, 23425), (20353, 21211), (20353, 3520), (20353, 10499), (20353, 16335), (20353, 26645), (20353, 16786), (20353, 4553), (20353, 15159), (20353, 10735), (20353, 2865), (20353, 440), (20353, 1441), (20353, 6307), (20353, 1503), (20353, 24948), (20353, 7846), (20353, 17565), (20353, 21973), (20353, 21833), (20353, 22007), (20353, 22165), (20353, 16663), (20353, 5525), (20353, 6969), (20353, 13086), (20353, 9158), (20353, 21508), (20353, 22015), (20353, 8245), (20353, 5230), (20353, 24770), (20353, 1785), (20353, 10814), (20353, 7186), (20353, 1638), (20353, 25910), (20353, 23679), (20353, 22521), (20353, 929), (20353, 465), (20353, 154), (20353, 24845), (20353, 5108), (20353, 22169), (20353, 15855), (20353, 22805), (20353, 10557), (20353, 4718), (20353, 23042), (20353, 16932), (20353, 805), (20353, 13492), (20353, 25587), (20353, 22874), (20353, 23334), (20353, 360), (20353, 2081), (20353, 23961), (20353, 22848), (20353, 16955), (20353, 6856), (20353, 2258), (20353, 27284), (20353, 13875)]\n",
    "problematic = list(itertools.chain(*problematic_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(v, labels, problematic_pairs, sample_size):\n",
    "    print(\"Generating net\")\n",
    "    smp, train, test, net = generate_net(v, labels, sample_size, problematic_pairs)\n",
    "    funcs_smp = smp.groupby(by='apn')['nf'].apply(set)\n",
    "\n",
    "    print(f\"Comparing classifications using net {len(net)} and full dataset ({len(train)})\")\n",
    "    net_hits = 0\n",
    "    train_hits = 0\n",
    "\n",
    "    for p in tqdm(test):\n",
    "        # classify the same point from test set using network and full train dataset\n",
    "        is_app_malware, net_class = verify_point(p, net, labels, k=2, distance=lambda x, y: adf(x, y, funcs_smp ))\n",
    "        is_app_malware, full_class = verify_point(p, train, labels, k=2,distance=lambda x, y: adf(x, y, funcs_smp ))\n",
    "        if is_app_malware == net_class:\n",
    "            net_hits+=1\n",
    "\n",
    "        if is_app_malware == full_class:\n",
    "            train_hits+=1\n",
    "        \n",
    "        if full_class!=net_class:\n",
    "            print(f\"Different classification result for {p}\")\n",
    "\n",
    "    print(f\"Net succes rate: {net_hits/len(test)}\")\n",
    "    print(f\"Full set sucess r: {train_hits/len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating net\n",
      "sample created 0.03\n",
      "Removing problematic 248 apps\n",
      "Split finished: 227851 malicious, 830408 bening, 1058259 overall\n",
      "Second removal of problematics 416\n",
      "Calculating net with 0.5\n",
      "Net 157 of 190 created\n",
      "Comparing classifications using net 157 and full dataset (190)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81a0450d731403c8197e92ec8e18275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=64.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Net succes rate: 0.90625\n",
      "Full set sucess r: 0.90625\n"
     ]
    }
   ],
   "source": [
    "check(v, labels, problematic_pairs, sample_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
